{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "330ee921-a6c6-4618-ae1f-1e0ae413af28",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: dask in /efs/users/xiet13/.conda/envs/hist_link/lib/python3.8/site-packages (2023.5.0)\n",
      "Requirement already satisfied: click>=8.0 in /efs/users/xiet13/.conda/envs/hist_link/lib/python3.8/site-packages (from dask) (8.1.7)\n",
      "Requirement already satisfied: cloudpickle>=1.5.0 in /efs/users/xiet13/.conda/envs/hist_link/lib/python3.8/site-packages (from dask) (3.0.0)\n",
      "Requirement already satisfied: fsspec>=2021.09.0 in /efs/users/xiet13/.conda/envs/hist_link/lib/python3.8/site-packages (from dask) (2023.9.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /efs/users/xiet13/.conda/envs/hist_link/lib/python3.8/site-packages (from dask) (23.1)\n",
      "Requirement already satisfied: partd>=1.2.0 in /efs/users/xiet13/.conda/envs/hist_link/lib/python3.8/site-packages (from dask) (1.4.1)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /efs/users/xiet13/.conda/envs/hist_link/lib/python3.8/site-packages (from dask) (6.0.1)\n",
      "Requirement already satisfied: toolz>=0.10.0 in /efs/users/xiet13/.conda/envs/hist_link/lib/python3.8/site-packages (from dask) (0.12.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.13.0 in /efs/users/xiet13/.conda/envs/hist_link/lib/python3.8/site-packages (from dask) (6.0.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /efs/users/xiet13/.conda/envs/hist_link/lib/python3.8/site-packages (from importlib-metadata>=4.13.0->dask) (3.11.0)\n",
      "Requirement already satisfied: locket in /efs/users/xiet13/.conda/envs/hist_link/lib/python3.8/site-packages (from partd>=1.2.0->dask) (1.0.0)\n",
      "Requirement already satisfied: pyarrow in /efs/users/xiet13/.conda/envs/hist_link/lib/python3.8/site-packages (13.0.0)\n",
      "Requirement already satisfied: numpy>=1.16.6 in /efs/users/xiet13/.conda/envs/hist_link/lib/python3.8/site-packages (from pyarrow) (1.24.4)\n",
      "Requirement already satisfied: recordlinkage in /efs/users/xiet13/.conda/envs/hist_link/lib/python3.8/site-packages (0.16)\n",
      "Requirement already satisfied: jellyfish>=1 in /efs/users/xiet13/.conda/envs/hist_link/lib/python3.8/site-packages (from recordlinkage) (1.0.1)\n",
      "Requirement already satisfied: numpy>=1.13 in /efs/users/xiet13/.conda/envs/hist_link/lib/python3.8/site-packages (from recordlinkage) (1.24.4)\n",
      "Requirement already satisfied: pandas<3,>=1 in /efs/users/xiet13/.conda/envs/hist_link/lib/python3.8/site-packages (from recordlinkage) (2.0.3)\n",
      "Requirement already satisfied: scipy>=1 in /efs/users/xiet13/.conda/envs/hist_link/lib/python3.8/site-packages (from recordlinkage) (1.10.1)\n",
      "Requirement already satisfied: scikit-learn>=1 in /efs/users/xiet13/.conda/envs/hist_link/lib/python3.8/site-packages (from recordlinkage) (1.3.1)\n",
      "Requirement already satisfied: joblib in /efs/users/xiet13/.conda/envs/hist_link/lib/python3.8/site-packages (from recordlinkage) (1.3.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /efs/users/xiet13/.conda/envs/hist_link/lib/python3.8/site-packages (from pandas<3,>=1->recordlinkage) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /efs/users/xiet13/.conda/envs/hist_link/lib/python3.8/site-packages (from pandas<3,>=1->recordlinkage) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /efs/users/xiet13/.conda/envs/hist_link/lib/python3.8/site-packages (from pandas<3,>=1->recordlinkage) (2023.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /efs/users/xiet13/.conda/envs/hist_link/lib/python3.8/site-packages (from scikit-learn>=1->recordlinkage) (3.2.0)\n",
      "Requirement already satisfied: six>=1.5 in /efs/users/xiet13/.conda/envs/hist_link/lib/python3.8/site-packages (from python-dateutil>=2.8.2->pandas<3,>=1->recordlinkage) (1.16.0)\n",
      "MemTotal:       258379312 kB\n",
      "MemFree:        66647516 kB\n",
      "MemAvailable:   79860932 kB\n",
      "Buffers:            2244 kB\n",
      "Cached:         14871160 kB\n",
      "SwapCached:            0 kB\n",
      "Active:          2280900 kB\n",
      "Inactive:       187813880 kB\n",
      "Active(anon):        988 kB\n",
      "Inactive(anon): 175221204 kB\n",
      "Active(file):    2279912 kB\n",
      "Inactive(file): 12592676 kB\n",
      "Unevictable:          28 kB\n",
      "Mlocked:              28 kB\n",
      "SwapTotal:             0 kB\n",
      "SwapFree:              0 kB\n",
      "Dirty:                16 kB\n",
      "Writeback:             0 kB\n",
      "AnonPages:      175217772 kB\n",
      "Mapped:           496912 kB\n",
      "Shmem:              1040 kB\n",
      "KReclaimable:     528320 kB\n",
      "Slab:             705364 kB\n",
      "SReclaimable:     528320 kB\n",
      "SUnreclaim:       177044 kB\n",
      "KernelStack:       14320 kB\n",
      "PageTables:       712972 kB\n",
      "NFS_Unstable:          0 kB\n",
      "Bounce:                0 kB\n",
      "WritebackTmp:          0 kB\n",
      "CommitLimit:    129189656 kB\n",
      "Committed_AS:   179491380 kB\n",
      "VmallocTotal:   34359738367 kB\n",
      "VmallocUsed:       23924 kB\n",
      "VmallocChunk:          0 kB\n",
      "Percpu:            17664 kB\n",
      "HardwareCorrupted:     0 kB\n",
      "AnonHugePages:  113588224 kB\n",
      "ShmemHugePages:        0 kB\n",
      "ShmemPmdMapped:        0 kB\n",
      "FileHugePages:         0 kB\n",
      "FilePmdMapped:         0 kB\n",
      "HugePages_Total:       0\n",
      "HugePages_Free:        0\n",
      "HugePages_Rsvd:        0\n",
      "HugePages_Surp:        0\n",
      "Hugepagesize:       2048 kB\n",
      "Hugetlb:               0 kB\n",
      "DirectMap4k:      212892 kB\n",
      "DirectMap2M:     7792640 kB\n",
      "DirectMap1G:    254803968 kB\n"
     ]
    }
   ],
   "source": [
    "!pip install -q pandas\n",
    "!pip install dask\n",
    "!pip install pyarrow\n",
    "!pip install fastparquet phonetics fuzzywuzzy jellyfish -q\n",
    "!pip install seaborn -q \n",
    "!pip install matplotlib -q \n",
    "\n",
    "import pandas as pd\n",
    "!pip install recordlinkage\n",
    "import recordlinkage as rl\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import dask.dataframe as dd\n",
    "import dask\n",
    "from recordlinkage.preprocessing import clean, phonetic\n",
    "\n",
    "def merge_tid_lmk(df):\n",
    "  # df = pd.merge(df, tran[[\"transactionid\", \"postcode\"]], on = \"transactionid\")\n",
    "  # df = pd.merge(df, tran[[\"postcode\"]].reset_index(), on = \"transactionid\")\n",
    "  df = pd.merge(df, tran.reset_index(), on = \"transactionid\")\n",
    "  df = df.rename(columns = {\"postcode\":\"postcode_tran\"})\n",
    "  # df = pd.merge(df, epc[[\"lmk\", \"postcode\"]], on = \"lmk\")\n",
    "  # df = pd.merge(df, epc[[\"postcode\"]].reset_index(), on = \"lmk\")\n",
    "  df = pd.merge(df, epc.reset_index(), on = \"lmk\")\n",
    "  df = df.rename(columns = {\"postcode\":\"postcode_epc\"})\n",
    "  return df\n",
    "\n",
    "def get_matches(df, cols):\n",
    "  df = df.reset_index()\n",
    "  df = merge_tid_lmk(df)\n",
    "  for col in cols:\n",
    "    df = df[df[col] != 0]\n",
    "  return df\n",
    "\n",
    "# get cpu number\n",
    "import multiprocessing\n",
    "multiprocessing.cpu_count()\n",
    "\n",
    "# get RAM\n",
    "!cat /proc/meminfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20ab9fea-599d-4d0e-92bf-1f60eb3065da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r-- 1 xiet13 cluster-users 780852725 Nov 19 18:08 ../Census_samples/Whole_ipum/Whole_1861\n"
     ]
    }
   ],
   "source": [
    "!ls -l ../Census_samples/Whole_ipum/Whole_1861"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a36afb84",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/xiet13/.conda/envs/hist_link/lib/python3.8/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.\n",
      "Perhaps you already have a cluster running?\n",
      "Hosting the HTTP server on port 34283 instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from dask.distributed import LocalCluster\n",
    "cluster = LocalCluster(n_workers=8, threads_per_worker=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "20a379a3-61ff-4b0a-9778-4da35be527dc",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# subSample1851 = dd.read_parquet('../Census_samples/Whole_ipum/Whole_1881').compute() # 17,711,030\n",
    "\n",
    "# _1851 = dd.read_parquet('../Census_samples/Whole_ipum/Whole_1851').compute()  \n",
    "# _1861 = dd.read_parquet('../Census_samples/Whole_ipum/Whole_1861').compute()  \n",
    "# _1881 = dd.read_parquet('../Census_samples/Whole_proc/Whole_1881').compute() \n",
    "# _1891 = dd.read_parquet('../Census_samples/Whole_proc/Whole_1891').compute() \n",
    "# _1901 = dd.read_parquet('../Census_samples/Whole_proc/Whole_1901').compute() \n",
    "_1911 = dd.read_parquet('../Census_samples/Whole_ipum/Whole_1911')\n",
    "# _1911 = dd.read_parquet('../Census_samples/Whole_ipum/Whole_1911').compute(scheduler = cluster) # need full treatment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8561e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "_1911"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "053aaf5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['recid', 'pname', 'sname', 'subdist_birth_ID', 'CONPARID_birth',\\\n",
    "                'recid_mom', 'recid_pop', 'recid_sp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b204c196",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "# _1851 = dd.read_parquet('../Census_samples/Whole_proc/Whole_1851')\n",
    "# _1891 = dd.read_parquet('../Census_samples/Whole_proc/Whole_1891')\n",
    "# _1901 = dd.read_parquet('../Census_samples/Whole_proc/Whole_1901')\n",
    "# _1911 = dd.read_parquet('../Census_samples/Whole_ipum/Whole_1911')\n",
    "\n",
    "# # # print folujns \n",
    "# # print(_1881.columns)\n",
    "# # print(_1891.columns)\n",
    "\n",
    "# # check if dateofbirth is in columns\n",
    "# print(\"dateofbirth\" in _1881.columns)\n",
    "# print(\"dateofbirth\" in _1891.columns)\n",
    "# print(\"dateofbirth\" in _1901.columns)\n",
    "# print(\"dateofbirth\" in _1911.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad9f194-b575-49ba-a9cb-35ab0fb5be06",
   "metadata": {},
   "source": [
    "### Phonetic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1557aa7b-30ec-43bb-91d9-12fd08e10db8",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 49s, sys: 23 s, total: 4min 12s\n",
      "Wall time: 4min 12s\n"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "# # \n",
    "# from recordlinkage.preprocessing import clean, phonetic\n",
    "# # get name \n",
    "# # pname: Possibly \"Personal Name\" or \"Given Name\", referring to the individual's first name.\n",
    "# # oname: Toname could potentially stand for \"Other Name,\" which might include middle names, initials, or other identifiers. \n",
    "# # It could also be a field where various types of data have been entered, possibly due to data collection methods or data quality issues.\n",
    "# # sname: This is generally understood to mean \"Surname\" or \"Family Name\", which is the individual's last name.\n",
    "\n",
    "# name_cols = ['pname', 'sname']\n",
    "# # age_cols = ['uk1861a_age']\n",
    "\n",
    "# def gt_interation(df, cols):\n",
    "#     # clean\n",
    "#     for col in cols:\n",
    "#         df[col] = clean(df[col], lowercase=False, remove_brackets=False)\n",
    "\n",
    "#     # phonetic\n",
    "#     for col in cols:\n",
    "#         df[f'{col}_soundex'] = phonetic(df[col], method = 'soundex')\n",
    "#     for col in cols:\n",
    "#         df[f'{col}_metaphone'] = phonetic(df[col], method = 'metaphone')\n",
    "        \n",
    "#     return df\n",
    "\n",
    "# # _1881 = gt_interation(_1881, name_cols)\n",
    "# _1881 = gt_interation(_1881, name_cols)\n",
    "# _1891 = gt_interation(_1891, name_cols)\n",
    "# # _1901 = gt_interation(_1901, name_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c6191155-9db4-458f-8234-1fa6a593977a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def convert_age_to_numeric(age):\n",
    "#     if age == 'less than 1 year':\n",
    "#         return 0\n",
    "#     elif age == '1 year':\n",
    "#         return 1\n",
    "#     elif age == '2 years':\n",
    "#         return 2\n",
    "#     elif age == '100+':\n",
    "#         return 100\n",
    "#     elif age == 'not reported/missing' or age == 'unkown':\n",
    "#         return np.nan\n",
    "#     else:\n",
    "#         try:\n",
    "#           return int(age)\n",
    "#         except ValueError:\n",
    "#           return np.nan\n",
    "\n",
    "# # Apply the function to the age column\n",
    "# census = {'1881':_1881, '1991':_1891}\n",
    "# # census = {'1891':_1891, '1901':_1901}\n",
    "# for k,v in census.items():\n",
    "#   # v['cap_pname'] = v.pname.str.strip().str[0]\n",
    "#   # v['cap_sname'] = v.sname.str.strip().str[0]\n",
    "\n",
    "#   # v['age_numeric'] = v[f'uk{k}a_cage'].apply(convert_age_to_numeric)\n",
    "#   v['dateofbirth'] = -v[f'uk{k}a_age'] + int(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8fc61bde-b173-416e-9d54-ae43faa3b6ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# _1891.to_parquet(\"../Census_samples/Whole_proc/Whole_1891\")\n",
    "# _1881.to_parquet(\"../Census_samples/Whole_proc/Whole_1881\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1757a4d4-78d1-47fd-9c6c-7cce003b1ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# subSample1861[['recid_mother', 'recid_father', 'recid_spouse', 'pname_mother',\n",
    "#        'sname_mother', 'subdist_birth_ID_mother', 'age_mother', 'pname_father',\n",
    "#        'sname_father', 'subdist_birth_ID_father', 'age_father', 'pname_spouse',\n",
    "#        'sname_spouse', 'subdist_birth_ID_spouse', 'age_spouse', 'pname_sibl1',\n",
    "#        'age_sibl1', 'pname_sibl2', 'age_sibl2', 'pname_sibl3', 'age_sibl3',\n",
    "#        'pname_sibl4', 'age_sibl4', 'pname_sibl5', 'age_sibl5', 'pname_sibl6',\n",
    "#        'age_sibl6', 'pname_sibl7', 'age_sibl7', 'pname_sibl8', 'age_sibl8',]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa22c30d-b872-45eb-b38e-d8a6e570abaf",
   "metadata": {},
   "source": [
    "### Feature engineering family ties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d46fcdbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import LocalCluster\n",
    "client = LocalCluster(n_workers=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3f45b9d8-d27c-4e33-916f-2c56fed7cb43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# _1881 = dd.read_parquet('../Census_samples/Whole_proc/Whole_1881')\n",
    "# _1891 = dd.read_parquet('../Census_samples/Whole_proc/Whole_1891')\n",
    "# _1901 = dd.read_parquet('../Census_samples/Whole_proc/Whole_1901') # print(\"dateofbirth\" in _1901.columns) # True\n",
    "_1911 = dd.read_parquet('../Census_samples/Whole_proc/Whole_1911') # print(\"dateofbirth\" in _1911.columns) # True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9dc03f8b-f28d-4847-8c14-2f410a7db18e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dask.delayed\n",
    "def fam_ties_mom_pop_sp_dask(df, year):\n",
    "    # Create a dictionary for each feature\n",
    "    # age_dict = df.set_index('recid')['age'].to_dict()\n",
    "\n",
    "    pname_dict = df.set_index('recid')['pname'].to_dict()\n",
    "    sname_dict = df.set_index('recid')['sname'].to_dict()\n",
    "    subdist_birth_id_dict = df.set_index('recid')['subdist_birth_ID'].to_dict()\n",
    "    conparid_birth_dict = df.set_index('recid')['CONPARID_birth'].to_dict()\n",
    "\n",
    "    # Map each dictionary to the respective new columns for mom, pop, and sp\n",
    "    # df['age_mom'] = df['recid_mom'].map(age_dict.get)\n",
    "    df['pname_mom'] = df['recid_mom'].map(pname_dict.get)\n",
    "    df['sname_mom'] = df['recid_mom'].map(sname_dict.get)\n",
    "    df['subdist_birth_ID_mom'] = df['recid_mom'].map(subdist_birth_id_dict.get)\n",
    "    df['CONPARID_birth_mom'] = df['recid_mom'].map(conparid_birth_dict.get)\n",
    "\n",
    "    # df['age_pop'] = df['recid_pop'].map(age_dict.get)\n",
    "    df['pname_pop'] = df['recid_pop'].map(pname_dict.get)\n",
    "    df['sname_pop'] = df['recid_pop'].map(sname_dict.get)\n",
    "    df['subdist_birth_ID_pop'] = df['recid_pop'].map(subdist_birth_id_dict.get)\n",
    "    df['CONPARID_birth_pop'] = df['recid_pop'].map(conparid_birth_dict.get)\n",
    "\n",
    "    # df['age_sp'] = df['recid_sp'].map(age_dict.get)\n",
    "    df['pname_sp'] = df['recid_sp'].map(pname_dict.get)\n",
    "    df['sname_sp'] = df['recid_sp'].map(sname_dict.get)\n",
    "    df['subdist_birth_ID_sp'] = df['recid_sp'].map(subdist_birth_id_dict.get)\n",
    "    df['CONPARID_birth_sp'] = df['recid_sp'].map(conparid_birth_dict.get)\n",
    "\n",
    "    df.to_parquet(f\"../Census_samples/Whole_proc/Whole_{year}_mom_pop_sp\")\n",
    "\n",
    "# fam_ties_mom_pop_sp_dask(_1881, \"1881\").compute()\n",
    "# fam_ties_mom_pop_sp_dask(_1891, \"1891\").compute()\n",
    "# fam_ties_mom_pop_sp_dask(_1901, \"1901\").compute()\n",
    "# fam_ties_mom_pop_sp_dask(_1911, \"1911\").compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5b2e7a13-66fe-4699-91cc-578293ba0adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "# _1881 = dd.read_parquet('../Census_samples/Whole_proc/Whole_1881_mom_pop_sp').compute()\n",
    "# _1891 = dd.read_parquet('../Census_samples/Whole_proc/Whole_1891_mom_pop_sp').compute()\n",
    "# _1901 = dd.read_parquet('../Census_samples/Whole_proc/Whole_1901_mom_pop_sp').compute()\n",
    "_1911 = dd.read_parquet('../Census_samples/Whole_proc/Whole_1911_mom_pop_sp').compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "de4254d3-5f6e-4b9f-a722-aa2b826152ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def phonetic_iteration(df, cols):\n",
    "    # clean\n",
    "    for col in cols:\n",
    "        df[col] = clean(df[col], lowercase=False, remove_brackets=False)\n",
    "\n",
    "    # phonetic\n",
    "    for col in cols:\n",
    "        df[f'{col}_soundex'] = phonetic(df[col], method = 'soundex')\n",
    "    for col in cols:\n",
    "        df[f'{col}_metaphone'] = phonetic(df[col], method = 'metaphone')\n",
    "        \n",
    "    return df\n",
    "\n",
    "# _1881 = gt_interation(_1881, name_cols)\n",
    "# _1881 = gt_interation(_1881, name_cols)\n",
    "# _1881 = phonetic_iteration(_1881, ['pname_mom', 'sname_mom', 'pname_pop', 'sname_pop',\n",
    "#                'pname_sp', 'sname_sp'])\n",
    "# _1891 = phonetic_iteration(_1891, ['pname_mom', 'sname_mom', 'pname_pop', 'sname_pop',\n",
    "#                'pname_sp', 'sname_sp'])\n",
    "# _1901 = phonetic_iteration(_1901, ['pname_mom', 'sname_mom', 'pname_pop', 'sname_pop',\n",
    "#                 'pname_sp', 'sname_sp'])\n",
    "_1911 = phonetic_iteration(_1911, ['pname_mom', 'sname_mom', 'pname_pop', 'sname_pop',\n",
    "                'pname_sp', 'sname_sp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6027787e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_1911.pname_pop_soundex.isna().sum() == _1911.pname_pop.isna().sum()\n",
    "_1911.pname_pop_metaphone.isna().sum() == _1911.pname_pop.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4e169763-c48d-484d-8787-2112978ef555",
   "metadata": {},
   "outputs": [],
   "source": [
    "# _1881.to_parquet(f\"../Census_samples/Whole_proc/Whole_{1881}_mom_pop_sp\")\n",
    "# _1891.to_parquet(f\"../Census_samples/Whole_proc/Whole_{1891}_mom_pop_sp\")\n",
    "# _1901.to_parquet(f\"../Census_samples/Whole_proc/Whole_{1901}_mom_pop_sp\")\n",
    "_1911.to_parquet(f\"../Census_samples/Whole_proc/Whole_{1911}_mom_pop_sp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ba1cc5-9d1f-4029-a2f9-222532df8fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# # Assuming 'subSample1851' has 'recid', 'age', 'recid_mother', 'recid_father' columns\n",
    "# # and 'pname_dict' and 'age_dict' are dictionaries mapping 'recid' to 'pname' and 'age' respectively.\n",
    "\n",
    "# # Helper function to create sibling features based on a groupby object\n",
    "# def create_sibling_features(df, parent_col):\n",
    "#     # Group by the parent column and list siblings, excluding the same row (sibling)\n",
    "#     sibling_info = df.groupby(parent_col)['recid'].apply(lambda x: x.tolist()).to_dict()\n",
    "\n",
    "#     # Create a DataFrame from the dictionary\n",
    "#     siblings_df = pd.DataFrame(list(sibling_info.items()), columns=[parent_col, 'siblings'])\n",
    "#     siblings_df = siblings_df.explode('siblings')\n",
    "#     siblings_df = siblings_df[siblings_df[parent_col] != siblings_df['siblings']]\n",
    "\n",
    "#     # Merge back with the original DataFrame to get the age of each sibling\n",
    "#     siblings_df = siblings_df.merge(df[['recid', 'age']], left_on='siblings', right_on='recid', suffixes=('', '_sib'))\n",
    "\n",
    "#     # Sort by age within each family\n",
    "#     # siblings_df.sort_values(by=[parent_col, 'age_sib'], inplace=True)\n",
    "\n",
    "#     # Drop unnecessary columns\n",
    "#     siblings_df.drop(columns=['recid'], inplace=True)\n",
    "\n",
    "#     return siblings_df\n",
    "\n",
    "# # Create sibling features for both mother and father\n",
    "# maternal_siblings_df = create_sibling_features(subSample1851, 'recid_mother')\n",
    "# paternal_siblings_df = create_sibling_features(subSample1851, 'recid_father')\n",
    "\n",
    "# # Function to score and sort siblings based on relatedness\n",
    "# def score_and_sort_siblings(maternal_df, paternal_df):\n",
    "#     # Merge maternal and paternal siblings on 'siblings' (the recid of the sibling)\n",
    "#     full_siblings_df = maternal_df.merge(paternal_df, on='siblings', suffixes=('_mat', '_pat'))\n",
    "#     full_siblings = full_siblings_df['siblings'].tolist()\n",
    "\n",
    "#     # Get half siblings from maternal and paternal, excluding full siblings\n",
    "#     half_siblings = set(maternal_df['siblings']).union(paternal_df['siblings']) - set(full_siblings)\n",
    "    \n",
    "#     return full_siblings + list(half_siblings)\n",
    "\n",
    "# # Now, we can iterate over the unique recids and create a sorted list of siblings\n",
    "# combined_sorted_siblings = {}\n",
    "# for recid in subSample1851['recid'].unique():\n",
    "#     maternal = maternal_siblings_df[maternal_siblings_df['recid_mother'] == recid]\n",
    "#     paternal = paternal_siblings_df[paternal_siblings_df['recid_father'] == recid]\n",
    "#     combined_sorted_siblings[recid] = score_and_sort_siblings(maternal, paternal)\n",
    "\n",
    "# # Map the personal name and age of siblings to the main DataFrame\n",
    "# max_siblings = 8\n",
    "# # for i in range(1, max_siblings + 1):\n",
    "# #     subSample1851[f'pname_sibl{i}'] = subSample1851['recid'].map(lambda x: pname_dict.get(combined_sorted_siblings.get(x, [None] * max_siblings)[i-1]))\n",
    "# #     subSample1851[f'age_sibl{i}'] = subSample1851['recid'].map(lambda x: age_dict.get(combined_sorted_siblings.get(x, [None] * max_siblings)[i-1]))\n",
    "# for i in range(1, max_siblings + 1):\n",
    "#     subSample1851[f'pname_sibl{i}'] = subSample1851['recid'].map(\n",
    "#         lambda x: pname_dict.get(\n",
    "#             combined_sorted_siblings.get(x, [None] * max_siblings)[i-1]\n",
    "#         ) if i <= len(combined_sorted_siblings.get(x, [])) else None\n",
    "#     )\n",
    "#     subSample1851[f'age_sibl{i}'] = subSample1851['recid'].map(\n",
    "#         lambda x: age_dict.get(\n",
    "#             combined_sorted_siblings.get(x, [None] * max_siblings)[i-1]\n",
    "#         ) if i <= len(combined_sorted_siblings.get(x, [])) else None\n",
    "#     )\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
